{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6284128725528717\n",
      "epoch= 0\n",
      "Accuracy is= tensor(37.7535)\n",
      "2.6236517594920263\n",
      "epoch= 1\n",
      "Accuracy is= tensor(31.2013)\n",
      "2.098679847187466\n",
      "epoch= 2\n",
      "Accuracy is= tensor(35.5694)\n",
      "1.5859713786178165\n",
      "epoch= 3\n",
      "Accuracy is= tensor(39.1576)\n",
      "1.3756964604059856\n",
      "epoch= 4\n",
      "Accuracy is= tensor(39.3136)\n",
      "1.155057892203331\n",
      "epoch= 5\n",
      "Accuracy is= tensor(42.9017)\n",
      "1.0806762956910663\n",
      "epoch= 6\n",
      "Accuracy is= tensor(42.9017)\n",
      "1.0351655897166994\n",
      "epoch= 7\n",
      "Accuracy is= tensor(44.3058)\n",
      "0.9834960119591819\n",
      "epoch= 8\n",
      "Accuracy is= tensor(44.3058)\n",
      "0.9215841641028722\n",
      "epoch= 9\n",
      "Accuracy is= tensor(43.5257)\n",
      "0.8680444210767746\n",
      "epoch= 10\n",
      "Accuracy is= tensor(43.2137)\n",
      "0.76985112660461\n",
      "epoch= 11\n",
      "Accuracy is= tensor(41.1856)\n",
      "0.7146502393815253\n",
      "epoch= 12\n",
      "Accuracy is= tensor(42.7457)\n",
      "0.6331641640928056\n",
      "epoch= 13\n",
      "Accuracy is= tensor(46.0218)\n",
      "0.5256885579890676\n",
      "epoch= 14\n",
      "Accuracy is= tensor(41.8097)\n",
      "0.4899928934044308\n",
      "epoch= 15\n",
      "Accuracy is= tensor(46.8019)\n",
      "0.35179262566897607\n",
      "epoch= 16\n",
      "Accuracy is= tensor(41.6537)\n",
      "0.26642698380682206\n",
      "epoch= 17\n",
      "Accuracy is= tensor(44.3058)\n",
      "0.2612633030447695\n",
      "epoch= 18\n",
      "Accuracy is= tensor(44.3058)\n",
      "0.19097837516003185\n",
      "epoch= 19\n",
      "Accuracy is= tensor(44.6178)\n",
      "0.15968639010356533\n",
      "epoch= 20\n",
      "Accuracy is= tensor(42.9017)\n",
      "0.14515214982546037\n",
      "epoch= 21\n",
      "Accuracy is= tensor(42.4337)\n",
      "0.11747483257204294\n",
      "epoch= 22\n",
      "Accuracy is= tensor(40.7176)\n",
      "0.08306572653560175\n",
      "epoch= 23\n",
      "Accuracy is= tensor(42.2777)\n",
      "0.0641868943348527\n",
      "epoch= 24\n",
      "Accuracy is= tensor(40.8736)\n",
      "0.05087043789939748\n",
      "epoch= 25\n",
      "Accuracy is= tensor(42.4337)\n",
      "0.06258864004889296\n",
      "epoch= 26\n",
      "Accuracy is= tensor(41.3417)\n",
      "0.07078347970835036\n",
      "epoch= 27\n",
      "Accuracy is= tensor(43.0577)\n",
      "0.06747681588037974\n",
      "epoch= 28\n",
      "Accuracy is= tensor(42.1217)\n",
      "0.07210143991849488\n",
      "epoch= 29\n",
      "Accuracy is= tensor(42.7457)\n",
      "0.13333143159333202\n",
      "epoch= 30\n",
      "Accuracy is= tensor(42.1217)\n",
      "0.16835206519398424\n",
      "epoch= 31\n",
      "Accuracy is= tensor(42.7457)\n",
      "0.2750508872171243\n",
      "epoch= 32\n",
      "Accuracy is= tensor(43.2137)\n",
      "0.32130994171732\n",
      "epoch= 33\n",
      "Accuracy is= tensor(41.3417)\n",
      "0.24421061792721352\n",
      "epoch= 34\n",
      "Accuracy is= tensor(44.3058)\n",
      "0.11561655682615107\n",
      "epoch= 35\n",
      "Accuracy is= tensor(46.4899)\n",
      "0.06344740209169686\n",
      "epoch= 36\n",
      "Accuracy is= tensor(46.3339)\n",
      "0.02522887144651678\n",
      "epoch= 37\n",
      "Accuracy is= tensor(46.1778)\n",
      "0.008358895911240123\n",
      "epoch= 38\n",
      "Accuracy is= tensor(45.2418)\n",
      "0.002332877767104138\n",
      "epoch= 39\n",
      "Accuracy is= tensor(45.3978)\n",
      "0.0012945863240424336\n",
      "epoch= 40\n",
      "Accuracy is= tensor(45.5538)\n",
      "0.0010480571420177715\n",
      "epoch= 41\n",
      "Accuracy is= tensor(45.7098)\n",
      "0.0009198806057813474\n",
      "epoch= 42\n",
      "Accuracy is= tensor(45.8658)\n",
      "0.0008282595226773992\n",
      "epoch= 43\n",
      "Accuracy is= tensor(45.5538)\n",
      "0.0006456891480613396\n",
      "epoch= 44\n",
      "Accuracy is= tensor(45.7098)\n",
      "0.0006420424817608566\n",
      "epoch= 45\n",
      "Accuracy is= tensor(45.7098)\n",
      "0.00061620699327452\n",
      "epoch= 46\n",
      "Accuracy is= tensor(45.8658)\n",
      "0.0005376058228042287\n",
      "epoch= 47\n",
      "Accuracy is= tensor(45.7098)\n",
      "0.0004953186705986607\n",
      "epoch= 48\n",
      "Accuracy is= tensor(45.5538)\n",
      "0.0004536360288006512\n",
      "epoch= 49\n",
      "Accuracy is= tensor(45.2418)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch import optim, nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as td\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "\n",
    "def custom_loader(batch_size, shuffle_test=False, data_path='./dataset/preprocessed'):\n",
    "    # Add the necessary transforms\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.225, 0.225, 0.225])\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((32, 32)),  # Adjust this if your images are a different size\n",
    "        transforms.ToTensor(),\n",
    "        normalize\n",
    "    ])\n",
    "\n",
    "    # Load your custom dataset\n",
    "    train_dataset = datasets.ImageFolder(root=data_path + '/train', transform=transform)\n",
    "    test_dataset = datasets.ImageFolder(root=data_path + '/test', transform=transform)\n",
    "\n",
    "    # Data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle_test, pin_memory=True)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "# Function to load CIFAR10 dataset\n",
    "def cifar_loader(batch_size, shuffle_test=False):\n",
    "    # Normalization values for CIFAR10 dataset\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.225, 0.225, 0.225])\n",
    "    # Loading training dataset with data augmentation techniques\n",
    "    train_dataset = datasets.CIFAR10('./data', train=True, download=True,\n",
    "    transform=transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, 4),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "    ]))\n",
    "    # Loading test dataset\n",
    "    test_dataset = datasets.CIFAR10('./data', train=False,\n",
    "    transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "    ]))\n",
    "    # Creating data loaders for training and testing\n",
    "    train_loader = td.DataLoader(train_dataset, batch_size=batch_size,\n",
    "    shuffle=True, pin_memory=True)\n",
    "    test_loader = td.DataLoader(test_dataset, batch_size=batch_size,\n",
    "    shuffle=shuffle_test, pin_memory=True)\n",
    "    return train_loader, test_loader\n",
    "# Hyperparameters and settings\n",
    "\n",
    "\n",
    "# class DataloaderName(Dataset):\n",
    "#     def __init__(self, inputprameters):\n",
    "#\n",
    "#         #codes\n",
    "#\n",
    "#     def __getitem__(self, index):\n",
    "#\n",
    "#         # code\n",
    "#\n",
    "#         return output\n",
    "#\n",
    "#     def __len__(self):\n",
    "#         return self.__data.shape[0]\n",
    "\n",
    "\n",
    "class MultiLayerFCNet(nn.Module):\n",
    "    def __init__(self,input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        # self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        # self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        self.layer1=nn.Conv2d(3,32,3,padding=1,stride=1)\n",
    "        self.B1 = nn.BatchNorm2d(32)\n",
    "        self.layer2 = nn.Conv2d(32, 32, 3, padding=1, stride=1)\n",
    "        self.B2 = nn.BatchNorm2d(32)\n",
    "        self.Maxpool=nn.MaxPool2d(2)\n",
    "        self.layer3 = nn.Conv2d(32, 64, 3, padding=1, stride=1)\n",
    "        self.B3 = nn.BatchNorm2d(64)\n",
    "        self.layer4 = nn.Conv2d(64, 64, 3, padding=1, stride=1)\n",
    "        self.B4 = nn.BatchNorm2d(64)\n",
    "        self.fc = nn.Linear(64*8*8, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = F.relu(self.fc1(x.view(x.size(0),-1)))\n",
    "        # x = F.relu(self.fc2(x))\n",
    "        # return F.log_softmax(self.fc3(x), dim=1)\n",
    "\n",
    "\n",
    "        x = self.B1(F.leaky_relu(self.layer1(x)))\n",
    "        x =  self.Maxpool(F.leaky_relu(self.layer2(x)))\n",
    "        x=self.B2(x)\n",
    "        x=self.B3(F.leaky_relu(self.layer3(x)))\n",
    "        x = self.B4(self.Maxpool(F.leaky_relu(self.layer4(x))))\n",
    "\n",
    "        return self.fc(x.view(x.size(0),-1))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    batch_size = 64\n",
    "    test_batch_size = 64\n",
    "    input_size = 3 * 32 * 32  # 3 channels, 32x32 image size\n",
    "    hidden_size = 50  # Number of hidden units\n",
    "    output_size = 4  # Number of output classes (CIFAR-10 has 10 classes)\n",
    "    num_epochs = 10\n",
    "\n",
    "    # train_loader, _ = cifar_loader(batch_size)\n",
    "    # _, test_loader = cifar_loader(test_batch_size)\n",
    "    train_loader, test_loader = custom_loader(batch_size, data_path='./dataset/preprocessed')\n",
    "    # dataloader = DataLoader(dataset=IrisDataset('iris.data'),\n",
    "    #                         batch_size=10,\n",
    "    #                         shuffle=True)\n",
    "\n",
    "    epochs = 50\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MultiLayerFCNet(input_size, hidden_size, output_size)\n",
    "    model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    #model.load_state_dict(torch.load('path'))\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    BestACC=0\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        for instances, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(instances)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(running_loss / len(train_loader))\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            allsamps=0\n",
    "            rightPred=0\n",
    "\n",
    "            for instances, labels in test_loader:\n",
    "\n",
    "                output = model(instances)\n",
    "                predictedClass=torch.max(output,1)\n",
    "                allsamps+=output.size(0)\n",
    "                rightPred+=(torch.max(output,1)[1]==labels).sum()\n",
    "\n",
    "\n",
    "            ACC=rightPred/allsamps\n",
    "            print(\"epoch=\",epoch)\n",
    "            print('Accuracy is=',ACC*100)\n",
    "            if ACC>BestACC:\n",
    "                BestACC=ACC\n",
    "                # torch.save(model.state_dict())\n",
    "                # torch.save(model.state_dict(), 'path')\n",
    "        model.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
