{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.571982271531049\n",
      "epoch= 0\n",
      "Accuracy is= tensor(22.1053)\n",
      "1.6658564104753382\n",
      "epoch= 1\n",
      "Accuracy is= tensor(22.4561)\n",
      "1.4200704495112102\n",
      "epoch= 2\n",
      "Accuracy is= tensor(28.7719)\n",
      "1.4066851209191715\n",
      "epoch= 3\n",
      "Accuracy is= tensor(30.3509)\n",
      "1.3762970975801057\n",
      "epoch= 4\n",
      "Accuracy is= tensor(31.7544)\n",
      "1.3745707133237053\n",
      "epoch= 5\n",
      "Accuracy is= tensor(30.8772)\n",
      "1.373191985429502\n",
      "epoch= 6\n",
      "Accuracy is= tensor(31.0526)\n",
      "1.3685651059244193\n",
      "epoch= 7\n",
      "Accuracy is= tensor(31.7544)\n",
      "1.3641673419989793\n",
      "epoch= 8\n",
      "Accuracy is= tensor(32.1053)\n",
      "1.3603496341144337\n",
      "epoch= 9\n",
      "Accuracy is= tensor(22.4561)\n",
      "1.346991031777625\n",
      "epoch= 10\n",
      "Accuracy is= tensor(27.7193)\n",
      "1.35363096816867\n",
      "epoch= 11\n",
      "Accuracy is= tensor(32.2807)\n",
      "1.3465139375013464\n",
      "epoch= 12\n",
      "Accuracy is= tensor(34.2105)\n",
      "1.325969424902224\n",
      "epoch= 13\n",
      "Accuracy is= tensor(31.9298)\n",
      "1.3117962327657962\n",
      "epoch= 14\n",
      "Accuracy is= tensor(34.9123)\n",
      "1.3027208950005325\n",
      "epoch= 15\n",
      "Accuracy is= tensor(29.8246)\n",
      "1.2624517235101438\n",
      "epoch= 16\n",
      "Accuracy is= tensor(34.5614)\n",
      "1.2341332014869242\n",
      "epoch= 17\n",
      "Accuracy is= tensor(41.4035)\n",
      "1.16004187336155\n",
      "epoch= 18\n",
      "Accuracy is= tensor(42.1053)\n",
      "1.0623266650181191\n",
      "epoch= 19\n",
      "Accuracy is= tensor(45.6140)\n",
      "0.974844146008585\n",
      "epoch= 20\n",
      "Accuracy is= tensor(49.6491)\n",
      "0.915373026155958\n",
      "epoch= 21\n",
      "Accuracy is= tensor(54.0351)\n",
      "0.8914774036874958\n",
      "epoch= 22\n",
      "Accuracy is= tensor(40.)\n",
      "0.8462457715296278\n",
      "epoch= 23\n",
      "Accuracy is= tensor(54.3860)\n",
      "0.8318939115486893\n",
      "epoch= 24\n",
      "Accuracy is= tensor(24.9123)\n",
      "0.7983952971065745\n",
      "epoch= 25\n",
      "Accuracy is= tensor(46.6667)\n",
      "0.7667234551672842\n",
      "epoch= 26\n",
      "Accuracy is= tensor(60.7018)\n",
      "0.7319630641563266\n",
      "epoch= 27\n",
      "Accuracy is= tensor(51.7544)\n",
      "0.7112127297064837\n",
      "epoch= 28\n",
      "Accuracy is= tensor(49.4737)\n",
      "0.699020689609004\n",
      "epoch= 29\n",
      "Accuracy is= tensor(53.8596)\n",
      "0.6406629219943402\n",
      "epoch= 30\n",
      "Accuracy is= tensor(50.8772)\n",
      "0.6199396106542325\n",
      "epoch= 31\n",
      "Accuracy is= tensor(63.3333)\n",
      "0.5716691361922844\n",
      "epoch= 32\n",
      "Accuracy is= tensor(55.7895)\n",
      "0.562833053224227\n",
      "epoch= 33\n",
      "Accuracy is= tensor(46.3158)\n",
      "0.531961474348517\n",
      "epoch= 34\n",
      "Accuracy is= tensor(61.2281)\n",
      "0.4962522802399654\n",
      "epoch= 35\n",
      "Accuracy is= tensor(58.7719)\n",
      "0.4972870244699366\n",
      "epoch= 36\n",
      "Accuracy is= tensor(59.2982)\n",
      "0.4606828902866326\n",
      "epoch= 37\n",
      "Accuracy is= tensor(56.3158)\n",
      "0.39869386512859195\n",
      "epoch= 38\n",
      "Accuracy is= tensor(54.9123)\n",
      "0.4062808681936825\n",
      "epoch= 39\n",
      "Accuracy is= tensor(61.9298)\n",
      "0.35065124549117743\n",
      "epoch= 40\n",
      "Accuracy is= tensor(64.9123)\n",
      "0.3199460500595616\n",
      "epoch= 41\n",
      "Accuracy is= tensor(61.7544)\n",
      "0.2807755140112896\n",
      "epoch= 42\n",
      "Accuracy is= tensor(60.8772)\n",
      "0.292196091483621\n",
      "epoch= 43\n",
      "Accuracy is= tensor(62.2807)\n",
      "0.2684086740893476\n",
      "epoch= 44\n",
      "Accuracy is= tensor(61.2281)\n",
      "0.2297181206590989\n",
      "epoch= 45\n",
      "Accuracy is= tensor(64.2105)\n",
      "0.1968322261875751\n",
      "epoch= 46\n",
      "Accuracy is= tensor(53.5088)\n",
      "0.2342932235960867\n",
      "epoch= 47\n",
      "Accuracy is= tensor(63.1579)\n",
      "0.17241763221282586\n",
      "epoch= 48\n",
      "Accuracy is= tensor(59.2982)\n",
      "0.178695800330709\n",
      "epoch= 49\n",
      "Accuracy is= tensor(58.4211)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torch import optim, nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as td\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "\n",
    "def custom_loader(batch_size, shuffle_test=False, data_path='./Dataset/Train'):\n",
    "    # Add the necessary transforms\n",
    "    # normalize = transforms.Normalize(mean=[0.024], std=[0.994])\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((48, 48)),  # Adjust this if your images are a different size\n",
    "        # transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n",
    "        transforms.ToTensor(),\n",
    "        # normalize\n",
    "    ])\n",
    "\n",
    "    # Load your dataset using ImageFolder\n",
    "    master_dataset = datasets.ImageFolder(root=data_path, transform=transform)\n",
    "\n",
    "    # Calculate the sizes of the splits\n",
    "    total_size = len(master_dataset)\n",
    "    train_size = int(0.85 * total_size)\n",
    "    val_size = total_size - train_size\n",
    "    # print(val_size)\n",
    "    # print(train_size)\n",
    "\n",
    "    # Use random_split to create datasets for training, testing, and validation\n",
    "    train_dataset, val_dataset = random_split(master_dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "\n",
    "class MultiLayerFCNet(nn.Module):\n",
    "    def __init__(self,input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        \n",
    "        self.layer1 = nn.Conv2d(3, 32, 5, padding=2, stride=1)\n",
    "        self.B1 = nn.BatchNorm2d(32)\n",
    "        self.layer2 = nn.Conv2d(32, 32, 5, padding=2, stride=1)\n",
    "        self.B2 = nn.BatchNorm2d(32)\n",
    "        self.Maxpool = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.layer3 = nn.Conv2d(32, 64, 5, padding=2, stride=1)\n",
    "        self.B3 = nn.BatchNorm2d(64)\n",
    "        self.layer4 = nn.Conv2d(64, 64, 5, padding=2, stride=1)\n",
    "        self.B4 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.layer5 = nn.Conv2d(64, 128, 5, padding=2, stride=1)\n",
    "        self.B5 = nn.BatchNorm2d(128)\n",
    "        self.layer6 = nn.Conv2d(128, 128, 5, padding=2, stride=1)\n",
    "        self.B6 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.layer7 = nn.Conv2d(128, 256, 5, padding=2, stride=1)\n",
    "        self.B7 = nn.BatchNorm2d(256)\n",
    "        self.layer8 = nn.Conv2d(256, 256, 5, padding=2, stride=1)\n",
    "        self.B8 = nn.BatchNorm2d(256)\n",
    "        self.layer9 = nn.Conv2d(256, 512, 5, padding=2, stride=1)\n",
    "        self.B9 = nn.BatchNorm2d(512)\n",
    "        self.layer10 = nn.Conv2d(512, 512, 5, padding=2, stride=1)\n",
    "        self.B10 = nn.BatchNorm2d(512)\n",
    "        self.Maxpool3 = nn.MaxPool2d(2)\n",
    "        self.Maxpool4 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.fc_size = 512 * 3 * 3  # Adjusted based on the added pooling layers\n",
    "        self.fc = nn.Linear(self.fc_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.B1(self.layer1(x)))\n",
    "        x = F.leaky_relu(self.B2(self.layer2(x)))\n",
    "        x = self.Maxpool(x)\n",
    "        \n",
    "        x = F.leaky_relu(self.B3(self.layer3(x)))\n",
    "        x = F.leaky_relu(self.B4(self.layer4(x)))\n",
    "        x = self.Maxpool(x)\n",
    "        \n",
    "        x = F.leaky_relu(self.B5(self.layer5(x)))\n",
    "        x = F.leaky_relu(self.B6(self.layer6(x)))\n",
    "        x = self.Maxpool3(x)\n",
    "        #print(x.shape)\n",
    "        x = F.leaky_relu(self.B7(self.layer7(x)))\n",
    "        x = F.leaky_relu(self.B8(self.layer8(x)))\n",
    "        x = self.Maxpool4(x)\n",
    "        \n",
    "        x = F.leaky_relu(self.B9(self.layer9(x)))\n",
    "        x = F.leaky_relu(self.B10(self.layer10(x)))\n",
    "        #print(x.shape)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor for the fully connected layer\n",
    "        return self.fc(x)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    batch_size = 64\n",
    "    test_batch_size = 64\n",
    "    input_size = 3 * 48 * 48  # 1 channels, 48x48 image size\n",
    "    hidden_size = 50  # Number of hidden units\n",
    "    output_size = 4  # Number of output classes 4\n",
    "    num_epochs = 10\n",
    "\n",
    "    # train_loader, _ = cifar_loader(batch_size)\n",
    "    # _, test_loader = cifar_loader(test_batch_size)\n",
    "    train_loader, test_loader = custom_loader(batch_size, data_path='./dataset/Train')\n",
    "    # dataloader = DataLoader(dataset=IrisDataset('iris.data'),\n",
    "    #                         batch_size=10,\n",
    "    #                         shuffle=True)\n",
    "\n",
    "    epochs = 50\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = MultiLayerFCNet(input_size, hidden_size, output_size)\n",
    "    model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    #model.load_state_dict(torch.load('path'))\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    BestACC=0.3\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        for instances, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(instances)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(running_loss / len(train_loader))\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            allsamps=0\n",
    "            rightPred=0\n",
    "\n",
    "            for instances, labels in test_loader:\n",
    "\n",
    "                output = model(instances)\n",
    "                predictedClass=torch.max(output,1)\n",
    "                allsamps+=output.size(0)\n",
    "                rightPred+=(torch.max(output,1)[1]==labels).sum()\n",
    "\n",
    "\n",
    "            ACC=rightPred/allsamps\n",
    "            print(\"epoch=\",epoch)\n",
    "            print('Accuracy is=',ACC*100)\n",
    "            #if the acc is greater than the best acc, save the model\n",
    "            \n",
    "            if ACC>BestACC:\n",
    "                torch.save(model.state_dict(), './model/model_variant2.pth')\n",
    "                BestACC=ACC\n",
    "\n",
    "            #save the model architecture\n",
    "\n",
    "            # torch.save(model, './model/model.pth')\n",
    "            # torch.save(model.state_dict(), './model/model_state_dict.pth')\n",
    "            # torch.save({\n",
    "            #     'model': model.state_dict(),\n",
    "            #     'optimizer': optimizer.state_dict(),\n",
    "            #     'epoch': epoch,\n",
    "            #     'loss': loss\n",
    "            # }, './model/all.tar')\n",
    "        model.train()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
